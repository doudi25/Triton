{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1X1etdEqp3LJdaFKprwth",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doudi25/Triton/blob/main/Sum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R5yFZNeLPPSQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import triton\n",
        "import triton.language as tl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.autotune(\n",
        "    configs=[ triton.Config({'BLOCK_SIZE_M':128,'BLOCK_SIZE_N':128},num_warps=4,num_stages=2),\n",
        "             triton.Config({'BLOCK_SIZE_M':256,'BLOCK_SIZE_N':256},num_warps=4,num_stages=4)],\n",
        "    key = ['m','n'])\n",
        "@triton.jit\n",
        "def sum_kernel(a_ptr,out_ptr,stride_am,stride_an,m,n,BLOCK_SIZE_M:tl.constexpr,BLOCK_SIZE_N:tl.constexpr):\n",
        "  pid_m = tl.program_id(axis=0)\n",
        "  pid_n = tl.program_id(axis=1)\n",
        "  offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0,BLOCK_SIZE_M)\n",
        "  offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0,BLOCK_SIZE_N)\n",
        "  mask = (offs_m[:,None] < m) & (offs_n[None,:] < n)\n",
        "  a = tl.load(a_ptr+offs_m[:,None] * stride_am+offs_n[None,:]*stride_an,mask=mask)\n",
        "  a = a.to(dtype=tl.float32)\n",
        "  out = tl.sum(a,axis=1,keep_dims=True)\n",
        "  out = out.to(dtype=tl.float32)\n",
        "  mask_out = offs_m[:,None] < m\n",
        "  tl.atomic_add(out_ptr+offs_m[:,None],out,mask=mask_out)"
      ],
      "metadata": {
        "id": "nvfr4WMiRdFv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sum(a:torch.tensor):\n",
        "  assert a.is_cuda and a.is_contiguous()\n",
        "  assert a.ndim > 1\n",
        "  m,n = a.shape\n",
        "  grid = lambda meta:(triton.cdiv(m,meta['BLOCK_SIZE_M']),triton.cdiv(n,meta['BLOCK_SIZE_N']))\n",
        "  out = torch.empty((m,1),device=a.device,dtype=a.dtype)\n",
        "  sum_kernel[grid](a,out,a.stride(0),a.stride(1),m,n)\n",
        "  return out"
      ],
      "metadata": {
        "id": "S6kRTipPPWlv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn((1024,2048),device='cuda')"
      ],
      "metadata": {
        "id": "0ZYRGL45RbVh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triton_sum = sum(a)\n",
        "torch_sum = a.sum(dim=1,keepdim=True)"
      ],
      "metadata": {
        "id": "_im2UIj0TxlQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.allclose(triton_sum,torch_sum,1e-3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sojg9IQKT1xP",
        "outputId": "0bdc1f05-37b0-4935-f340-566b21d805ea"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    }
  ]
}