{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5MSNgqCo9qhZ+a3ENDn6I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doudi25/Triton/blob/main/Flash_Attention_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5AoLcjAew2-z"
      },
      "outputs": [],
      "source": [
        "import triton\n",
        "import triton.language as tl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _attn_fwd_inner(\n",
        "          O_block,\n",
        "          l_i,\n",
        "          m_i,\n",
        "          Q_block,\n",
        "          K_block_ptr,\n",
        "          V_block_ptr,\n",
        "          pid_q,\n",
        "          softmax_scale,\n",
        "          BLOCK_SIZE_Q: tl.constexpr,\n",
        "          BLOCK_SIZE_KV: tl.constexpr,\n",
        "          STAGE: tl.constexpr,\n",
        "          offs_q: tl.constexpr,\n",
        "          offs_kv: tl.constexpr,\n",
        "          SEQ_LEN: tl.constexpr,):\n",
        "  if STAGE==1:\n",
        "    lo, hi = 0, pid_q * BLOCK_SIZE_Q\n",
        "  elif STAGE ==2 :\n",
        "    lo, hi = pid_q * BLOCK_SIZE_Q, (pid_q + 1) * BLOCK_SIZE_Q\n",
        "    lo = tl.multiple_of(lo,BLOCK_SIZE_Q)\n",
        "  else:\n",
        "    lo,hi = 0, SEQ_LEN\n",
        "  K_block_ptr = tl.advance(K_block_ptr,(0,lo))\n",
        "  V_block_ptr = tl.advance(V_block_ptr,(lo,0))\n",
        "  for start_kv in range(lo,hi,BLOCK_SIZE_KV):\n",
        "    start_kv = tl.multiple_of(start_kv,BLOCK_SIZE_KV)\n",
        "    K_block = tl.load(K_block_ptr)\n",
        "    QK_block = tl.dot(Q_block, K_block)\n",
        "    if STAGE==2:\n",
        "      mask = offs_q[:,None] >= (start_kv + offs_kv[None,:])\n",
        "      QK_block = QK_block * softmax_scale + tl.where(mask,0,-1.0e6)\n",
        "      m_ij = tl.maximum(m_i,tl.max(QK_BLOCK,1))\n",
        "      QK_block -= m_ij[:,None]\n",
        "    else:\n",
        "      m_ij = tl.maximum(m_i,tl.max(QK_block,1) * sofmtax_scale)\n",
        "      QK_block = QK_block * softmax_scale -m_ij[:,None]\n",
        "    P_block = tl.math.exp(QK_block)\n",
        "    l_ij = tl.sum(P_block,1)\n",
        "    alpha = tl.math.exp(m_i - m_ij)\n",
        "    l_i = l_i * alpha + l_ij\n",
        "    V_block = tl.load(V_block_ptr)\n",
        "    P_block = P_block.to(tl.float16)\n",
        "    O_block = O_block * alpha[:,None]\n",
        "    O_block = tl.dot(P_block,V_block,O_block)\n",
        "    m_i = m_ij\n",
        "    V_block_ptr = tl.advance(V_block_ptr,(BLOCK_SIZE_KV,0))\n",
        "    K_block_ptr = tl.advance(K_block_ptr,(0,BLOCK_SIZE_KV))\n",
        "  return O_block, l_i, m_i\n",
        "\n",
        "@triton.autotune(\n",
        "    [\n",
        "        triton.Config(\n",
        "            {\"BLOCK_SIZE_Q\": BLOCK_SIZE_Q, \"BLOCK_SIZE_KV\": BLOCK_SIZE_KV},\n",
        "            num_stages=num_stages,\n",
        "            num_warps=num_warps,\n",
        "        )\n",
        "        for BLOCK_SIZE_Q in [16, 32]\n",
        "        for BLOCK_SIZE_KV in [16, 32]\n",
        "        for num_stages in ([3,4,7])\n",
        "        for num_warps in [2,4]\n",
        "    ],\n",
        "    key=[\"SEQ_LEN\", \"HEAD_DIM\"],)\n",
        "@triton.jit\n",
        "def _attn_fwd(\n",
        "    Q,K,V,\n",
        "    softmax_scale,\n",
        "    M,O,\n",
        "    stride_Q_batch,\n",
        "    stride_Q_head,\n",
        "    stride_Q_seq,\n",
        "    stride_Q_dim,\n",
        "    stride_V_batch,\n",
        "    stride_V_head,\n",
        "    stride_V_seq,\n",
        "    stride_V_dim,\n",
        "    stride_K_batch,\n",
        "    stride_K_head,\n",
        "    stride_K_seq,\n",
        "    stride_K_dim,\n",
        "    stride_O_batch,\n",
        "    stride_O_head,\n",
        "    stride_O_seq,\n",
        "    stride_O_dim,\n",
        "    BATCH_SIZE,\n",
        "    NUM_HEADS: tl.constexpr,\n",
        "    SEQ_LEN: tl.constexpr,\n",
        "    HEAD_DIM: tl.constexpr,\n",
        "    BLOCK_SIZE_Q: tl.constexpr,\n",
        "    BLOCK_SIZE_KV: tl.constexpr,\n",
        "    STAGE:tl.constexpr,):\n",
        " # tl.static_assert(BLOCK_SIZE_KV<=HEAD_DIM)\n",
        "    pid_q = tl.program_id(axis=0)\n",
        "    block_index_q = pid_q\n",
        "    index_batch_head = tl.program_id(axis=1)\n",
        "    # the index_batch is updated each NUM_HEADS steps , need to pass through all the heads in the batch to jump to the next batch\n",
        "    index_batch = index_batch_head // NUM_HEADS\n",
        "    # use modulo because the heads index repeated for each batch , so for batch 0 [h0,h1,h2,h3] -> batch 1 [h0,h1,h2,h3] and so one\n",
        "    index_head = index_batch_head % NUM_HEADS\n",
        "    qvk_offset = (\n",
        "        index_batch.to(tl.int64) * stride_Q_batch + index_head.to(tl.int64) * stride_Q_head)\n",
        "    qkv_offset = qvk_offset\n",
        "    offset_q = pid_q * BLOCK_SIZE_Q + tl.arange(0,BLOCK_SIZE_Q)\n",
        "    offset_head = tl.arange(0,HEAD_DIM)\n",
        "    offset_kv = tl.arange(0,BLOCK_SIZE_KV)\n",
        "    # offset[:,None] convert the offset to column vector with shape (len(offset),1) and offset[None,:] convert to row vector\n",
        "    Q_block_ptr = Q + qkv_offset + offset_q[:,None] * stride_Q_seq + offset_head[None,:] * stride_Q_dim\n",
        "    K_block_ptr = K + qkv_offset + offset_head[:,None] * stride_K_dim + offset_kv[None,:] * stride_K_seq\n",
        "    V_block_ptr = V + qkv_offset + offset_kv[:,None] * stride_V_seq + offset_head[None,:] * stride_V_dim\n",
        "    O_block_ptr = O + qkv_offset + offset_q[:,None] * stride_O_seq + offset_head[None,:] * stride_O_dim\n",
        "\n",
        "    Q_block = tl.load(Q_block_ptr)\n",
        "    m_i = tl.zeros([BLOCK_SIZE_Q],dtype=tl.float32) - float(\"inf\")\n",
        "    l_i = tl.zeros([BLOCK_SIZE_Q],dtype=tl.float32) + 1.0\n",
        "    O_block = tl.zeros([BLOCK_SIZE_Q,HEAD_DIM],dtype=tl.float32)\n",
        "    if STAGE == 1 or STAGE == 3:\n",
        "      O_block, l_i, m_i = _attn_fwd_inner(\n",
        "          O_block,\n",
        "          l_i,\n",
        "          m_i,\n",
        "          Q_block,\n",
        "          K_block_ptr,\n",
        "          V_block_ptr,\n",
        "          pid_q,\n",
        "          softmax_scale,\n",
        "          BLOCK_SIZE_Q,\n",
        "          BLOCK_SIZE_KV,\n",
        "          4 - STAGE,\n",
        "          offset_q,\n",
        "          offset_kv,\n",
        "          SEQ_LEN,\n",
        "      )\n",
        "    if STAGE ==3:\n",
        "      O_block, l_i, m_i = _attn_fwd_inner(\n",
        "          O_block,\n",
        "          l_i,\n",
        "          m_i,\n",
        "          Q_block,\n",
        "          K_block_ptr,\n",
        "          V_block_ptr,\n",
        "          block_index_q,\n",
        "          softmax_scale,\n",
        "          BLOCK_SIZE_Q,\n",
        "          BLOCK_SIZE_KV,\n",
        "          2,\n",
        "          offs_q,\n",
        "          offs_kv,\n",
        "          SEQ_LEN,)\n",
        "    m_i += tl.math.log(\n",
        "        l_i)\n",
        "    O_block = O_block / l_i[:,None]\n",
        "    m_ptrs = M + index_batch_head * SEQ_LEN + offs_q\n",
        "    tl.store(m_ptrs, m_i)\n",
        "    tl.store(O_block_ptr, O_block.to(O.type.element_ty))\n",
        "@triton.jit\n",
        "def _attn_bwd_preprocess(\n",
        "      O,\n",
        "      dO,\n",
        "      D, # same shape of M batch_size , nbr_heads, seq_len\n",
        "      SEQ_LEN,\n",
        "      BLOCK_SIZE_Q:tl.constexpr,\n",
        "      HEAD_DIM: tl.constexpr,):\n",
        "  block_index_q = tl.program_id(0) # which group of vector we re going to work with grid => seq_len/macro , batch*nbr_heads\n",
        "  offs_q = block_index_q * BLOCK_SIZE_Q + tl.arange(0,BLOCK_SIZE_Q)\n",
        "  index_batch_head = tl.program_id(1)\n",
        "  offs_dim = tl.arange(0,HEAD_DIM)\n",
        "  # HEAD_DIM * SEQ_LEN == O.stride(1) stride of heads to jump from head to another you need to skip HEAD_DIM * SEQ_LEN elements\n",
        "  # HEAD_DIM is the stride of SEQ_LEN dimension\n",
        "  # here is the same configuration as in the forward pass\n",
        "  O_dO_ptr =  index_batch_head * HEAD_DIM * SEQ_LEN + offs_q[:,None] * HEAD_DIM + offs_dim[None,:]\n",
        "  O_block = tl.load(O_dO_ptr+ O_ptr).to(tl.float32)\n",
        "  dO_block = tl.load(O_dO_ptr + dO).to(tl.float32)\n",
        "  D_block = tl.sum(dO_block * O_block,axis=1)\n",
        "  D_block_ptrs = D + index_batch_head * SEQ_LEN + offs_q[None,:]\n",
        "  tl.store(D_block_ptrs,D_block)\n",
        "@triton.jit\n",
        "def _attn_bwd_dq(\n",
        "    Q,\n",
        "    K,\n",
        "    V,\n",
        "    softmax_scale,\n",
        "    dO,\n",
        "    dQ,\n",
        "    dK,\n",
        "    dV,\n",
        "    M,\n",
        "    D,\n",
        "    stride_batch,\n",
        "    stride_head,\n",
        "    stride_seq,\n",
        "    stride_dim,\n",
        "    NUM_HEADS,\n",
        "    SEQ_LEN,\n",
        "    BLOCK_Q: tl.constexpr,\n",
        "    BLOCK_KV: tl.constexpr,\n",
        "    HEAD_DIM: tl.constexpr,\n",
        "    STAGE: tl.constexpr,):\n",
        "    # same configuration of dk dv backward , read it first\n",
        "    index_batch_head = tl.program_id(2)\n",
        "    index_batch = index_batch_head // NUM_HEADS\n",
        "    index_head = index_batch_head % NUM_HEADS\n",
        "    offset_batch_head = (stride_batch * index_batch + stride_head * index_head).to(\n",
        "        tl.int64\n",
        "    )\n",
        "    offset_batch_head_seq = (index_batch_head * SEQ_LEN).to(tl.int64)\n",
        "\n",
        "    Q += offset_batch_head\n",
        "    K += offset_batch_head\n",
        "    V += offset_batch_head\n",
        "    dO += offset_batch_head\n",
        "    dQ += offset_batch_head\n",
        "    dK += offset_batch_head\n",
        "    dV += offset_batch_head\n",
        "\n",
        "    M += offset_batch_head_seq\n",
        "    D += offset_batch_head_seq\n",
        "\n",
        "    offs_dim = tl.arange(0, HEAD_DIM)\n",
        "\n",
        "    index_block_kv = tl.program_id(0)\n",
        "\n",
        "    start_q = index_block_kv * BLOCK_Q\n",
        "    offs_q = start_q + tl.arange(0, BLOCK_Q)\n",
        "\n",
        "    Q_block = tl.load(Q + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim)\n",
        "    dQ_block = tl.zeros([BLOCK_Q, HEAD_DIM], dtype=tl.float32)\n",
        "    dO_block = tl.load(\n",
        "        dO + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
        "    )\n",
        "\n",
        "    M_block = tl.load(M + offs_q)\n",
        "    M_block = M_block[:, None]\n",
        "\n",
        "    offs_kv = tl.arange(0, BLOCK_KV)\n",
        "\n",
        "    # We access the K and V as transposed blocks\n",
        "    kT_ptrs = K + offs_kv[None, :] * stride_seq + offs_dim[:, None] * stride_dim\n",
        "    vT_ptrs = V + offs_kv[None, :] * stride_seq + offs_dim[:, None] * stride_dim\n",
        "\n",
        "    Di = tl.load(D + offs_q)\n",
        "\n",
        "    curr_kv = 0\n",
        "    num_steps = SEQ_LEN // BLOCK_KV\n",
        "    for blk_idx in range(num_steps):\n",
        "        K_T_block = tl.load(kT_ptrs)\n",
        "        V_T_block = tl.load(vT_ptrs)\n",
        "        QK_block = softmax_scale * tl.dot(Q_block, K_T_block)\n",
        "        P_block = tl.math.exp(QK_block - M_block)\n",
        "\n",
        "        if STAGE == 3:\n",
        "            # mask the values that are above the diagonal ( causal masking )\n",
        "            offs_kv = curr_kv + tl.arange(0, BLOCK_KV)\n",
        "            mask_block = offs_q[:, None] >= offs_kv[None, :]\n",
        "            P_block = tl.where(mask_block, P_block, 0.0)\n",
        "\n",
        "        # follow the algorithm by compute dP and dS in order to compute dQ\n",
        "        dP_block = tl.dot(dO_block, V_T_block).to(tl.float32)\n",
        "        dS_block = P_block * (dP_block - Di[:, None])\n",
        "        dS_block = dS_block.to(tl.float16)\n",
        "        dQ_block += softmax_scale * tl.dot(dS_block, tl.trans(K_T_block)) # taw in flash attention algorithm is the softmax_scale\n",
        "        # jump pointers by BLOCK_KV * stride_seq (stride_seq is equal to head_dim because to jump from sequence to sequence need to pass through all head_dim values).\n",
        "        curr_kv += BLOCK_KV\n",
        "        kT_ptrs += BLOCK_KV * stride_seq\n",
        "        vT_ptrs += BLOCK_KV * stride_seq\n",
        "\n",
        "    dQ_block_ptrs = dQ + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
        "    tl.store(dQ_block_ptrs, dQ_block)\n",
        "\n",
        "@triton.jit\n",
        "def _attn_bwd_dk_dv(\n",
        "      Q,\n",
        "      K,\n",
        "      V,\n",
        "      softmax_scale,\n",
        "      dO,\n",
        "      dQ,\n",
        "      dK,\n",
        "      dV,\n",
        "      M,\n",
        "      D,\n",
        "      stride_batch,\n",
        "      stride_head,\n",
        "      stride_seq,\n",
        "      stride_dim,\n",
        "      NUM_HEADS,\n",
        "      SEQ_LEN,\n",
        "      BLOCK_Q: tl.constexpr,\n",
        "      BLOCK_KV: tl.constexpr,\n",
        "      HEAD_DIM: tl.constexpr,\n",
        "      STAGE: tl.constexpr):\n",
        "    index_batch_head = tl.program_id(2)\n",
        "    index_batch = index_batch_head // NUM_HEADS\n",
        "    index_head = index_batch_head % NUM_HEADS\n",
        "    offset_batch_head = (stride_batch * index_batch + stride_heads * index_head).to(tl.int64)\n",
        "    offset_batch_head_seq = ( index_batch_head * SEQ_LEN).to(tl.int64) # equivalent to index_batch * SEQ_LEN * NUM_HEADS + index_head * SEQ_LEN\n",
        "    offs_dim = tl.arange(0,HEAD_DIM)\n",
        "    index_block_kv = tl.program_id(0) # since we fix the macro which deal with kv block , fixed kv and loop through others (following flash attention 2 algorithm)\n",
        "    start_kv = index_block_kv * BLOCK_KV\n",
        "    offs_kv = start_kv + tl.arange(0,BLOCK_KV)\n",
        "    Q += offset_batch_head\n",
        "    K += offset_batch_head\n",
        "    V += offset_batch_head\n",
        "    dO += offset_batch_head\n",
        "    dQ += offset_batch_head\n",
        "    dK += offset_batch_head\n",
        "    dV += offset_batch_head\n",
        "    M += offset_batch_head\n",
        "    D += offset_batch_head\n",
        "    dV_block = tl.zeros([BLOCK_KV,HEAD_DIM],dtype=tl.float32)\n",
        "    dK_block = tl.zeros([BLOCK_KV,HEAD_DIM],dtype=tl.float32)\n",
        "    K_block = tl.load(K + offs_kv[:,None] * stride_seq + offs_dim[None,:] * stride_dim)\n",
        "    V_block = tl.load(V + offs_kv[:,None] * stride_seq + offs_dim[None,:] * stride_dim)\n",
        "    offs_q = tl.arange(0,BLOCK_Q)\n",
        "    qT_ptrs = Q + offs_q[None,:] * stride_seq + offs_dim[:,None] * stride_dim\n",
        "    dO_ptrs = dO + offs_q[:,None] * stride_seq + offs_dim[None,:] * stride_dim\n",
        "    curr_q = 0\n",
        "    num_steps = SEQ_LEN // BLOCK_Q\n",
        "    for blk_idx in range(num_steps):\n",
        "      qT_block = tl.load(qT_ptrs)\n",
        "      offs_q = curr_q + tl.arange(0, BLOCK_Q)\n",
        "      m = tl.load(M + offs_q)\n",
        "      QK_T_block = softmax_scale * tl.dot(K_block,qT_block)\n",
        "      P_T_block = tl.math.exp(QK_T_block - m[None,:])\n",
        "\n",
        "      if STAGE == 3:\n",
        "        mask_block = (\n",
        "            offs_q[None,:] >= offs_kv[:,None]) # since we are working with Q_T the seq_len becomes in cols axis and KV has seq_len in rows axis\n",
        "            # create 2d tensor mask to enable causal masking ( mask the values that are above the diagonal )\n",
        "        P_T_block = tl.where(mask_block, P_T_block,0.0)\n",
        "      dO_block = tl.load(dO_ptrs)\n",
        "      dV_block += tl.dot(P_T_block.to(tl.float16),dO_block)\n",
        "      Di = tl.load(D + offs_q)\n",
        "      dpT_block = tl.dot(V_block,tl.trans(dO_block)).to(tl.float32)\n",
        "      dS_T_block = P_T_block * (dpT_block - Di[None,:])\n",
        "      dS_T_block = dS_T_block.to(tl.float16)\n",
        "      dK_block += softmax_scale * tl.dot(dS_T_block,tl.trans(qT_block))\n",
        "      curr_q += BLOCK_Q\n",
        "      qT_ptrs += BLOCK_Q * stride_seq\n",
        "      dO_ptrs += BLOCK_Q * stride_seq\n",
        "    dV_block_ptrs = dV + offs_kv[:,None] * stride_seq + offs_dim[None,:] * stride_dim\n",
        "    tl.store(dV_block_ptrs,dV_block)\n",
        "    dK_block_ptrs = dK + offs_kv[:,None] * stride_seq + offs_dim[None,:] * stride_dim\n",
        "    tl.store(dK_block_ptrs,dK_block)"
      ],
      "metadata": {
        "id": "wHnrOyQPw0xX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TritonAttention(torch.autograd.Function):\n",
        "  @staticmethod\n",
        "  def forward(ctx,Q,K,V,causal,softmax_scale):\n",
        "    HEAD_DIM_Q,HEAD_DIM_K = Q.shape[-1],K.shape[-1]\n",
        "    HEAD_DIM_V = V.shape[-1]\n",
        "    BATCH_SIZE,NUM_HEADS,SEQ_LEN,HEAD_DIM = Q.shape\n",
        "    assert HEAD_DIM_Q == HEAD_DIM_K and HEAD_DIM_K == HEAD_DIM_K\n",
        "    O = torch.empty_like(Q)\n",
        "    stage = 3 if causal else 1\n",
        "    grid = lambda args : (\n",
        "        triton.cdiv(SEQ_LEN,args['BLOCK_SIZE_Q']),\n",
        "        BATCH_SIZE * NUM_HEADS,\n",
        "        1,)\n",
        "    M = torch.empty((BATCH_SIZE,NUM_HEADS,SEQ_LEN),device=Q.device,dtype=torch.float32)\n",
        "    _attn_fwd[grid](\n",
        "            Q=Q,\n",
        "            K=K,\n",
        "            V=V,\n",
        "            softmax_scale=softmax_scale,\n",
        "            M=M,\n",
        "            O=O,\n",
        "            stride_Q_batch=Q.stride(0),\n",
        "            stride_Q_head=Q.stride(1),\n",
        "            stride_Q_seq=Q.stride(2),\n",
        "            stride_Q_dim=Q.stride(3),\n",
        "            stride_K_batch=K.stride(0),\n",
        "            stride_K_head=K.stride(1),\n",
        "            stride_K_seq=K.stride(2),\n",
        "            stride_K_dim=K.stride(3),\n",
        "            stride_V_batch=V.stride(0),\n",
        "            stride_V_head=V.stride(1),\n",
        "            stride_V_seq=V.stride(2),\n",
        "            stride_V_dim=V.stride(3),\n",
        "            stride_O_batch=O.stride(0),\n",
        "            stride_O_head=O.stride(1),\n",
        "            stride_O_seq=O.stride(2),\n",
        "            stride_O_dim=O.stride(3),\n",
        "            BATCH_SIZE=Q.shape[0],\n",
        "            NUM_HEADS=Q.shape[1],\n",
        "            SEQ_LEN=Q.shape[2],\n",
        "            HEAD_DIM=HEAD_DIM_K,\n",
        "            STAGE=stage,\n",
        "        )\n",
        "    ctx.save_for_backward(Q,K,V,O,M)\n",
        "    ctx.grid = grid\n",
        "    ctx.softmax_scale = sftmax_scale\n",
        "    ctx.HEAD_DIM = HEAD_DIM_K\n",
        "    ctx.causal = causal\n",
        "    return O\n",
        "  @staticmethod\n",
        "  def backward(ctx, dO):\n",
        "    Q, K, V, O, M = ctx.saved_tensors\n",
        "    assert dO.is_contiguous()\n",
        "    assert Q.stride() == K.stride() == V.stride() == O.stride() == dO.stride()\n",
        "    dQ = torch.empty_like(Q)\n",
        "    dK = torch.empty_like(K)\n",
        "    dV = torch.empty_like(V)\n",
        "    BATCH_SIZE, NUM_HEADS, SEQ_LEN = Q.shape[:3]\n",
        "    NUM_WARPS, NUM_STAGES = 4, 3\n",
        "    BLOCK_SIZE_MICRO, BLOCK_SIZE_MACRO = 32, 128\n",
        "    preprocess_grid = (SEQ_LEN // BLOCK_SIZE_MACRO, BATCH_SIZE * NUM_HEADS)\n",
        "    D = torch.empty_like(M)\n",
        "    _attn_bwd_preprocess[preprocess_grid](\n",
        "        O=O,\n",
        "        dO=dO,\n",
        "        D=D,\n",
        "        SEQ_LEN=SEQ_LEN,\n",
        "        BLOCK_SIZE_Q=BLOCK_SIZE_MACRO,\n",
        "        HEAD_DIM=ctx.HEAD_DIM,)\n",
        "    grid = (SEQ_LEN // BLOCK_SIZE_MACRO, 1, BATCH_SIZE * NUM_HEADS)\n",
        "    stage = 3 if ctx.causal else 1\n",
        "    _attn_bwd_dk_dv[grid](\n",
        "        Q=Q,\n",
        "        K=K,\n",
        "        V=V,\n",
        "        softmax_scale=ctx.softmax_scale,\n",
        "        dO=dO,\n",
        "        dQ=dQ,\n",
        "        dK=dK,\n",
        "        dV=dV,\n",
        "        M=M,\n",
        "        D=D,\n",
        "        stride_batch=Q.stride(0),\n",
        "        stride_head=Q.stride(1),\n",
        "        stride_seq=Q.stride(2),\n",
        "        stride_dim=Q.stride(3),\n",
        "        NUM_HEADS=NUM_HEADS,\n",
        "        SEQ_LEN=SEQ_LEN,\n",
        "        BLOCK_Q=BLOCK_SIZE_MICRO,\n",
        "        BLOCK_KV=BLOCK_SIZE_MACRO,\n",
        "        HEAD_DIM=ctx.HEAD_DIM,\n",
        "        STAGE=stage,\n",
        "        num_warps=NUM_WARPS,\n",
        "        num_stages=NUM_STAGES,)\n",
        "    _attn_bwd_dq[grid](\n",
        "            Q=Q,\n",
        "            K=K,\n",
        "            V=V,\n",
        "            softmax_scale=ctx.softmax_scale,\n",
        "            dO=dO,\n",
        "            dQ=dQ,\n",
        "            dK=dK,\n",
        "            dV=dV,\n",
        "            M=M,\n",
        "            D=D,\n",
        "            stride_batch=Q.stride(0),\n",
        "            stride_head=Q.stride(1),\n",
        "            stride_seq=Q.stride(2),\n",
        "            stride_dim=Q.stride(3),\n",
        "            NUM_HEADS=NUM_HEADS,\n",
        "            SEQ_LEN=SEQ_LEN,\n",
        "            BLOCK_Q=BLOCK_SIZE_MACRO,\n",
        "            BLOCK_KV=BLOCK_SIZE_MICRO,\n",
        "            HEAD_DIM=ctx.HEAD_DIM,\n",
        "            STAGE=stage,\n",
        "            num_warps=NUM_WARPS,\n",
        "            num_stages=NUM_STAGES,\n",
        "        )\n",
        "    return dQ, dK, dV, None, None\n",
        "\n"
      ],
      "metadata": {
        "id": "DeQp-kXWrphf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_op(BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM, causal, dtype=torch.float16):\n",
        "    Q = (\n",
        "        torch.empty(\n",
        "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
        "        )\n",
        "        .normal_(mean=0.0, std=0.5)\n",
        "        .requires_grad_()\n",
        "    )\n",
        "    K = (\n",
        "        torch.empty(\n",
        "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
        "        )\n",
        "        .normal_(mean=0.0, std=0.5)\n",
        "        .requires_grad_()\n",
        "    )\n",
        "    V = (\n",
        "        torch.empty(\n",
        "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
        "        )\n",
        "        .normal_(mean=0.0, std=0.5)\n",
        "        .requires_grad_()\n",
        "    )\n",
        "\n",
        "    softmax_scale = 1 / (HEAD_DIM**0.5)\n",
        "    dO = torch.randn_like(Q)\n",
        "\n",
        "    # reference implementation\n",
        "    MASK = torch.tril(torch.ones((SEQ_LEN, SEQ_LEN), device=\"cuda\"))\n",
        "    P = torch.matmul(Q, K.transpose(2, 3)) * softmax_scale\n",
        "    if causal:\n",
        "        P[:, :, MASK == 0] = float(\"-inf\")\n",
        "    P = torch.softmax(P.float(), dim=-1).half()\n",
        "    ref_O = torch.matmul(P, V)\n",
        "    ref_O.backward(dO)\n",
        "    ref_dV, V.grad = V.grad.clone(), None\n",
        "    ref_dK, K.grad = K.grad.clone(), None\n",
        "    ref_dQ, Q.grad = Q.grad.clone(), None\n",
        "\n",
        "    # triton implementation\n",
        "    tri_out = TritonAttention.apply(Q, K, V, causal, softmax_scale).half()\n",
        "    tri_out.backward(dO)\n",
        "    tri_dV, V.grad = V.grad.clone(), None\n",
        "    tri_dK, K.grad = K.grad.clone(), None\n",
        "    tri_dQ, Q.grad = Q.grad.clone(), None\n",
        "\n",
        "    # compare\n",
        "    rtol = 0.0\n",
        "    atol = 1e-2\n",
        "    assert torch.allclose(ref_O, tri_out, atol=atol, rtol=rtol)\n",
        "    assert torch.allclose(ref_dK, tri_dK, atol=atol, rtol=rtol)\n",
        "    assert torch.allclose(ref_dV, tri_dV, atol=atol, rtol=rtol)\n",
        "    assert torch.allclose(ref_dQ, tri_dQ, atol=atol, rtol=rtol)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_op(BATCH_SIZE=2, NUM_HEADS=4, SEQ_LEN=16, HEAD_DIM=32, causal=True)\n",
        "    print(\"GPU Memory Allocated:\", torch.cuda.memory_allocated())\n",
        "    print(\"GPU Memory Reserved:\", torch.cuda.memory_reserved())\n",
        "    #test_op(BATCH_SIZE=1, NUM_HEADS=1, SEQ_LEN=2, HEAD_DIM=4, causal=False)\n",
        "    print(\"PASSED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD_PPPinZqpS",
        "outputId": "7b73204c-4a47-42dc-f662-829b72384681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:825: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sqaDRgCIfaCR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}