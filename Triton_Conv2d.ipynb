{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGlObKjfCpDCuI8mNLnOAU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doudi25/Triton/blob/main/Triton_Conv2d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5u5_E-wiVJhN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "from typing import Tuple\n",
        "\n",
        "dtype = torch.float32\n",
        "device = 'cuda:0'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def conv2d_kernel(\n",
        "    input_ptr,input_batch_stride,input_channel_stride,input_row_stride,\n",
        "    input_col_stride, height, width,channels, kernel_ptr, kernel_height, kernel_width, kernel_dim_stride,\n",
        "    kernel_channel_stride, kernel_row_stride, kernel_col_stride, bias_ptr,output_ptr, output_width, output_batch_stride,\n",
        "    output_channel_stride, output_row_stride,output_col_stride, BLOCK_SIZE_ROW: tl.constexpr,  BLOCK_SIZE_COL: tl.constexpr,num_stages: tl.constexpr):\n",
        "  batch_id = tl.program_id(axis=0)\n",
        "  kernel_id = tl.program_id(axis=1)\n",
        "  row_id = tl.program_id(axis=2)\n",
        "  # since bias length is equal to num_kernels , so to access is use (bias_ptr + kernel_id)\n",
        "  bias_offset = kernel_id\n",
        "  bias = tl.load(bias_ptr + bias_offset)\n",
        "  # offset by batch for input\n",
        "  in_batch_offs = batch_id * input_batch_stride\n",
        "  # out_offs is assigned by batch * stride_batch and kernel_id * stride_channel because num kernels rely on the 1 dim of the output\n",
        "  out_offs = batch_id * output_batch_stride + kernel_id * output_channel_stride + row_id * output_row_stride\n",
        "  kernel_row_offs = tl.arange(0,BLOCK_SIZE_ROW)\n",
        "  kernel_col_offs = tl.arange(0,BLOCK_SIZE_COL)\n",
        "  # apply the mask\n",
        "  kernel_mask = (kernel_row_offs[:,None] < kernel_height) &(kernel_col_offs[None,:] < kernel_width)\n",
        "  # assign the offset for the kernel\n",
        "  kernel_offs = kernel_row_offs[:,None] * kernel_row_stride + kernel_col_offs[None,:] * kernel_col_stride\n",
        "  # input_row_offs depend on kernel_height because we assign each (groupe rows to thread blocks ) group_rows = height // kernel_height\n",
        "  input_row_offs = row_id * kernel_height + tl.arange(0,BLOCK_SIZE_ROW)\n",
        "  input_row_mask = input_row_offs[:,None] < height\n",
        "  input_row_offs = input_row_offs[:,None] * input_row_stride\n",
        "  # iterate trough the columns , for each group_rows , group_cols we do element wise mul and sum , across all input channels\n",
        "  for col_id in range(output_width):\n",
        "    elem = 0.0\n",
        "    # for each group_cols = input_width // kernel_width we assign the offs\n",
        "    input_col_offs = col_id * kernel_width + tl.arange(0,BLOCK_SIZE_COL)\n",
        "    # assign the mask\n",
        "    input_col_mask = input_col_offs[None,:] < width\n",
        "    input_col_offs = input_col_offs[None,:] * input_col_stride\n",
        "    # iterate trough each chanel (depth of image)\n",
        "    for c in range(channels,num_stages=num_stages):\n",
        "      # assign the correct block of pointer to load the inputs\n",
        "      input_ptrs = input_ptr + in_batch_offs + c * input_channel_stride + input_row_offs + input_col_offs\n",
        "      input = tl.load(input_ptrs,mask=(input_row_mask)&(input_col_mask))\n",
        "      # assing the correct block of pointer for the kernel -> for each kernel we have depth == depth of image\n",
        "      kernel_ptrs = kernel_ptr + kernel_id * kernel_dim_stride + c * kernel_channel_stride + kernel_offs\n",
        "      # load the values\n",
        "      kernel = tl.load(kernel_ptrs,mask=kernel_mask)\n",
        "      # element wise multiplication and sum\n",
        "      elem += tl.sum(input * kernel).to(dtype=tl.float32)\n",
        "\n",
        "    out_ptrs = output_ptr + out_offs + col_id\n",
        "    tl.store(out_ptrs,elem+bias)\n"
      ],
      "metadata": {
        "id": "haNoPKjTi-Fi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_triton(\n",
        "    input: torch.Tensor,\n",
        "    kernel: torch.Tensor,\n",
        "    bias: torch.Tensor\n",
        ") -> torch.Tensor:\n",
        "    assert input.is_cuda and kernel.is_cuda, 'Input or kernel is not on GPU'\n",
        "    assert len(input.shape) == 4, f'Input needs to be 4 dimensional, provided: {input.shape}'\n",
        "    assert len(kernel.shape) == 4, f'Kernel size needs to be 4 dimensional, provided: {kernel.shape}'\n",
        "    assert bias.shape[0] == kernel.shape[0], f'Bias dimension should be same as the kernel 1st dimension'\n",
        "\n",
        "    batch_size, channels, height, width = input.shape\n",
        "    # num_kernels == num_out_channels , kernel_depth = num_in_channels\n",
        "    num_kernels, kernel_depth, kernel_height, kernel_width = kernel.shape\n",
        "    # assert compatibility between height and kernel_height , to match it\n",
        "    assert height%kernel_height == 0 and width%kernel_width == 0, f\"Input height and width should be divisible by the kernel height and width\"\n",
        "    assert channels == kernel_depth, f\"Kernel channel depth ({kernel_depth}) and input channel depth ({channels}) should be same\"\n",
        "\n",
        "    output = torch.empty((batch_size, num_kernels, height//kernel_height, width//kernel_width), device=device, dtype=dtype)\n",
        "    # next_power_of_2 gives the pow(2,n) that is equal to kernel_height or bigger then it\n",
        "    BLOCK_SIZE_ROW = triton.next_power_of_2(kernel_height)\n",
        "    BLOCK_SIZE_COL = triton.next_power_of_2(kernel_width)\n",
        "    # parallelize across the batch and kernels and grouped rows (groupe rows = kernel_height)\n",
        "    grid = (batch_size, num_kernels, height//kernel_height)\n",
        "\n",
        "    conv2d_kernel[grid](\n",
        "        input_ptr=input,\n",
        "        input_batch_stride=input.stride(0),\n",
        "        input_channel_stride=input.stride(1),\n",
        "        input_row_stride=input.stride(2),\n",
        "        input_col_stride=input.stride(3),\n",
        "        height=height,\n",
        "        width=width,\n",
        "        channels=channels,\n",
        "        kernel_ptr=kernel,\n",
        "        kernel_height=kernel_height,\n",
        "        kernel_width=kernel_width,\n",
        "        kernel_dim_stride=kernel.stride(0),\n",
        "        kernel_channel_stride=kernel.stride(1),\n",
        "        kernel_row_stride=kernel.stride(2),\n",
        "        kernel_col_stride=kernel.stride(3),\n",
        "        bias_ptr=bias,\n",
        "        output_ptr=output,\n",
        "        output_width=width//kernel_width,\n",
        "        output_batch_stride=output.stride(0),\n",
        "        output_channel_stride=output.stride(1),\n",
        "        output_row_stride=output.stride(2),\n",
        "        output_col_stride=output.stride(3),\n",
        "        BLOCK_SIZE_ROW=BLOCK_SIZE_ROW,\n",
        "        BLOCK_SIZE_COL=BLOCK_SIZE_COL,\n",
        "        num_stages=4,)\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "NOY2SZcdWefR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = torch.nn.Conv2d(3,8,(4,4),4).to('cuda')\n",
        "input = torch.rand((1,3,40,40),device='cuda')\n",
        "out = layer(input)\n",
        "out_triton = conv2d_triton(input,layer.weight,layer.bias)"
      ],
      "metadata": {
        "id": "slQ4Eglkd0DZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.allclose(out,out_triton,1e-4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMCX3V_MdQ-V",
        "outputId": "a4958517-f0c9-4dd8-dc01-33958db8e3d3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    }
  ]
}