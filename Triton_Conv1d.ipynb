{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3Th2iGBMeJN+kWtTcnSbo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doudi25/Triton/blob/main/Triton_Conv1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xqRNMk0SLzQl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import triton\n",
        "import triton.language as tl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer = nn.Conv1d(4,7,3,3).to('cuda')\n",
        "input = torch.rand((4,4,9),device='cuda')\n",
        "out = layer(input)\n",
        "layer.weight.shape\n",
        "layer.bias.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTRRvmHzOUCS",
        "outputId": "f43c8848-a79e-4b70-80aa-2cd48894621b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def conv1d_kernel(input_ptr,input_batch_stride,\n",
        "        input_channel_stride,\n",
        "        input_col_stride,\n",
        "        width,\n",
        "        channels,\n",
        "        kernel_ptr,\n",
        "        kernel_width,\n",
        "        kernel_dim_stride,\n",
        "        kernel_channel_stride,\n",
        "        kernel_col_stride,\n",
        "        bias_ptr,\n",
        "        output_ptr,\n",
        "        output_width,\n",
        "        output_batch_stride,\n",
        "        output_channel_stride,\n",
        "        output_col_stride,\n",
        "        BLOCK_SIZE_COL:tl.constexpr,\n",
        "        BLOCK_SIZE_CHANNELS:tl.constexpr):\n",
        "  batch_id = tl.program_id(axis=0)\n",
        "  kernel_id = tl.program_id(axis=1)\n",
        "  col_id = tl.program_id(axis=2)\n",
        "  input_offs = batch_id * input_batch_stride\n",
        "  kernel_offs = kernel_id * kernel_dim_stride\n",
        "  channel_offs = tl.arange(0,BLOCK_SIZE_CHANNELS)\n",
        "  channel_mask = channel_offs[:,None] < channels\n",
        "  channel_kernel_offs = channel_offs[:,None] * kernel_channel_stride\n",
        "  channel_offs = channel_offs[:,None] * input_channel_stride\n",
        "  col_offs =  tl.arange(0,BLOCK_SIZE_COL)\n",
        "  col_kernel_mask = col_offs[None,:] < kernel_width\n",
        "  col_kernel_offs = col_offs[None,:] * kernel_col_stride\n",
        "  col_offs = col_id * kernel_width + tl.arange(0,BLOCK_SIZE_COL)\n",
        "  mask_col = col_offs[None,:] < width\n",
        "  col_offs = col_offs[None,:] * input_col_stride\n",
        "  bias = tl.load(bias_ptr+kernel_id)\n",
        "  input_ptrs = input_ptr + input_offs+ channel_offs + col_offs\n",
        "  input  = tl.load(input_ptrs,mask=(channel_mask) & (mask_col))\n",
        "  kernel_ptrs = kernel_ptr + kernel_offs + channel_kernel_offs + col_kernel_offs\n",
        "  kernel = tl.load(kernel_ptrs,mask=(channel_mask) & (col_kernel_mask))\n",
        "  elem = tl.sum(input * kernel) + bias\n",
        "  out_ptrs = output_ptr + output_batch_stride * batch_id + output_channel_stride * kernel_id + col_id\n",
        "  tl.store(out_ptrs,elem)"
      ],
      "metadata": {
        "id": "El7C7mJPRSDR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Triton_Conv1d(input,kernel,bias):\n",
        "  assert input.is_cuda and kernel.is_cuda, 'Input or kernel is not on GPU'\n",
        "  assert input.ndim == 3, f'Input needs to be 4 dimensional, provided: {input.shape}'\n",
        "  assert kernel.ndim == 3, f'Kernel size needs to be 4 dimensional, provided: {kernel.shape}'\n",
        "  assert bias.shape[0] == kernel.shape[0], f'Bias dimension should be same as the kernel 1st dimension'\n",
        "  batch_size,channels,width = input.shape\n",
        "  num_kernels,kernel_depth,kernel_width = kernel.shape\n",
        "  assert width % kernel_width == 0,f'invalid compatibility {width} is not multiple of {kernel_width}'\n",
        "  assert channels == kernel_depth, f\"Kernel channel depth ({kernel_depth}) and input channel depth ({channels}) should be same\"\n",
        "  output = torch.empty((batch_size,num_kernels,width//kernel_width),device=input.device)\n",
        "  BLOCK_SIZE_COL = triton.next_power_of_2(kernel_width)\n",
        "    # parallelize across the batch and kernels and grouped rows (groupe rows = kernel_height)\n",
        "  grid = (batch_size, num_kernels, width//kernel_width)\n",
        "  conv1d_kernel[grid](\n",
        "        input_ptr=input,\n",
        "        input_batch_stride=input.stride(0),\n",
        "        input_channel_stride=input.stride(1),\n",
        "        input_col_stride=input.stride(2),\n",
        "        width=width,\n",
        "        channels=channels,\n",
        "        kernel_ptr=kernel,\n",
        "        kernel_width=kernel_width,\n",
        "        kernel_dim_stride=kernel.stride(0),\n",
        "        kernel_channel_stride=kernel.stride(1),\n",
        "        kernel_col_stride=kernel.stride(2),\n",
        "        bias_ptr=bias,\n",
        "        output_ptr=output,\n",
        "        output_width=width//kernel_width,\n",
        "        output_batch_stride=output.stride(0),\n",
        "        output_channel_stride=output.stride(1),\n",
        "        output_col_stride=output.stride(2),\n",
        "        BLOCK_SIZE_COL=BLOCK_SIZE_COL,\n",
        "        BLOCK_SIZE_CHANNELS=channels)\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "L2IFG4HFOmRY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = nn.Conv1d(4,12,16,16).to('cuda')\n",
        "input = torch.rand((16,4,64),device='cuda')\n",
        "out_triton = Triton_Conv1d(input,layer.weight,layer.bias)\n",
        "out = layer(input)"
      ],
      "metadata": {
        "id": "DpoJ0PyvWFfC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.allclose(out,out_triton,1e-4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYdOgLHdYWaJ",
        "outputId": "6c1cc77a-214d-45b0-bee3-eef50b5fd840"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    }
  ]
}