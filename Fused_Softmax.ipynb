{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMikAcvqtG2qvIzfwn/NCJf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doudi25/Triton/blob/main/Fused_Softmax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a89c6gYkOOD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def softmax_kernel(y_ptr,out_ptr,M,N,stride_ym,stride_yn\n",
        "                   ,ROW_BLOCK:tl.constexpr,BLOCK_SIZE:tl.constexpr,\n",
        "                   num_stages:tl.constexpr):\n",
        "  program_id = tl.program_id(axis=0)\n",
        "  offset_m = program_id * ROW_BLOCK + tl.arange(0,ROW_BLOCK)\n",
        "  offset_n = tl.arange(0,BLOCK_SIZE)\n",
        "  y_ptrs = y_ptr + offset_m[:,None] * stride_ym + offset_n[None,:] * stride_yn\n",
        "  out_ptrs = out_ptr + offset_m[:,None] * stride_ym + offset_n[None,:] * stride_yn\n",
        "  mask = offset_n < N\n",
        "  y = tl.load(y_ptrs,mask=mask[None,:],other=-float('inf'))\n",
        "  y_max = tl.max(y,axis=1)\n",
        "  exp = tl.exp(y - y_max[:,None])\n",
        "  sum = tl.sum(exp,axis=1)\n",
        "  out = exp / sum[:,None]\n",
        "  tl.store(out_ptrs,out,mask=mask[None,:])\n",
        "\n"
      ],
      "metadata": {
        "id": "tKl2AF2Q8MuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(y):\n",
        "  assert y.is_contiguous()\n",
        "  M, N = y.shape\n",
        "  out = torch.empty_like(y,device=y.device)\n",
        "  BLOCK_SIZE = triton.next_power_of_2(N)\n",
        "def softmax(y):\n",
        "  assert y.is_contiguous()\n",
        "  M, N = y.shape\n",
        "  out = torch.empty_like(y,device=y.device)\n",
        "  BLOCK_SIZE = triton.next_power_of_2(N)\n",
        "  grid = lambda meta: (triton.cdiv(M,4),)\n",
        "  num_stages = 2\n",
        "  softmax_kernel[grid](y,out,M,N,y.stride(0),y.stride(1),ROW_BLOCK=4,BLOCK_SIZE=BLOCK_SIZE,num_stages=num_stages)\n",
        "  return out"
      ],
      "metadata": {
        "id": "afJYBdYAoTTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "x = torch.randn(1823, 781, device='cuda')\n",
        "y_triton = softmax(x)\n",
        "y_torch = torch.softmax(x, axis=1)\n",
        "assert torch.allclose(y_triton, y_torch), (y_triton, y_torch)"
      ],
      "metadata": {
        "id": "F4sDURsD--04"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}