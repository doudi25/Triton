{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZNO/qRIEjcy3RvvpDwOjm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doudi25/Triton/blob/main/AvgPool2d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import triton\n",
        "import triton.language as tl"
      ],
      "metadata": {
        "id": "eUXigh3_vPDm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def AvgPool2d_kernel(\n",
        "    image_ptr, out_ptr,\n",
        "    stride_i0, stride_i1, stride_i2, stride_i3,\n",
        "    stride_o0, stride_o1, stride_o2, stride_o3,\n",
        "    H, W, k_h, k_w,BLOCK_SIZE_ROW: tl.constexpr, BLOCK_SIZE_COL: tl.constexpr,num_warps=2,num_stages=2):\n",
        "  pid_bs = tl.program_id(axis=0)\n",
        "  pid_ch = tl.program_id(axis=1)\n",
        "  pid_2 = tl.program_id(axis=2)\n",
        "  nbr_pid_w = W // k_w\n",
        "  pid_w = pid_2 % nbr_pid_w\n",
        "  pid_h = pid_2 // nbr_pid_w\n",
        "  offs_row = pid_h * k_h + tl.arange(0,BLOCK_SIZE_ROW)\n",
        "  offs_col = pid_w* k_w + tl.arange(0,BLOCK_SIZE_COL)\n",
        "  mask  = (offs_row[:,None] < H) & (offs_col[None,:] < W)\n",
        "  offs_row_ker = tl.arange(0,BLOCK_SIZE_ROW)\n",
        "  offs_col_ker = tl.arange(0,BLOCK_SIZE_COL)\n",
        "  mask_ker = (offs_row_ker[:,None] < k_h) & (offs_col_ker[None,:] < k_w)\n",
        "  input_ptrs = image_ptr + pid_bs * stride_i0 + pid_ch * stride_i1 + offs_row[:,None] * stride_i2 + offs_col[None,:] * stride_i3\n",
        "  input = tl.load(input_ptrs,mask=mask)\n",
        "  input = tl.where(mask_ker,input,0.0)\n",
        "  elem = tl.sum(input) / (k_h * k_w)\n",
        "  out_ptrs = out_ptr + pid_bs * stride_o0 + pid_ch * stride_o1 + pid_h * stride_o2 + pid_w\n",
        "  tl.store(out_ptrs,elem)"
      ],
      "metadata": {
        "id": "Vz9Em2rtKNqo"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avgpool2d(image:torch.tensor,kernel_shape:tuple):\n",
        "  assert image.is_cuda and image.is_contiguous()\n",
        "  assert image.ndim == 4\n",
        "  bs,c,h,w = image.shape\n",
        "  k_h, k_w = kernel_shape[0],kernel_shape[1]\n",
        "  assert h % k_h == 0 and w % k_w == 0\n",
        "  out = torch.empty((bs,c,h//k_h,w//k_w),device=image.device,dtype=image.dtype)\n",
        "  BLOCK_SIZE_ROW = triton.next_power_of_2(k_h)\n",
        "  BLOCK_SIZE_COL = triton.next_power_of_2(k_w)\n",
        "  grid = (bs,c,triton.cdiv(h,k_h)*triton.cdiv(w,k_w))\n",
        "  AvgPool2d_kernel[grid](image,out,image.stride(0),image.stride(1),image.stride(2),\n",
        "                         image.stride(3),out.stride(0),out.stride(1),out.stride(2),\n",
        "                         out.stride(3),h,w,k_h,k_w,BLOCK_SIZE_ROW,BLOCK_SIZE_COL)\n",
        "  return out"
      ],
      "metadata": {
        "id": "EcZhMdnK5Ovs"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avgpool = nn.AvgPool2d(kernel_size=(16,16),stride=(16,16)).to('cuda')\n",
        "image = torch.randn((12,8,64,64),device='cuda')\n",
        "out = avgpool(image)\n",
        "out_triton = avgpool2d(image,avgpool.kernel_size)"
      ],
      "metadata": {
        "id": "nLq-rM025idQ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.allclose(out,out_triton,1e-3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug1jPY00OFG9",
        "outputId": "62c44bee-2c84-42d4-b89c-4fb4365f53dd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark(fn,*args,warmup=8,steps=128):\n",
        "  start = torch.cuda.Event(enable_timing=True)\n",
        "  end = torch.cuda.Event(enable_timing=True)\n",
        "  for _ in range(warmup):\n",
        "    fn(*args)\n",
        "  torch.cuda.synchronize()\n",
        "  start.record()\n",
        "  for _ in range(steps):\n",
        "    fn(*args)\n",
        "  end.record()\n",
        "  torch.cuda.synchronize()\n",
        "  return start.elapsed_time(end) / steps"
      ],
      "metadata": {
        "id": "XMb5P7gqObwo"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shapes = [\n",
        "    (2, 8, 64, 64),\n",
        "    (2, 16, 32, 32),\n",
        "    (4, 8, 64, 64),\n",
        "    (4, 16, 32, 32),]\n",
        "images = [torch.randn(shape, device='cuda', dtype=torch.float32) for shape in shapes]\n",
        "triton_time = [benchmark(avgpool2d,image,avgpool.kernel_size) for image in images]\n",
        "torch_time =  [benchmark(lambda a,b:avgpool(a),image,avgpool.kernel_size) for image in image]"
      ],
      "metadata": {
        "id": "0TePWa1mO8P9"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "# Create a PrettyTable\n",
        "table = PrettyTable()\n",
        "table.field_names = [\"Shape\", \"Triton Time (ms)\", \"PyTorch Time (ms)\"]\n",
        "\n",
        "# Add rows to the table\n",
        "for shape, triton_t, torch_t in zip(shapes, triton_time, torch_time):\n",
        "    table.add_row([shape, f\"{triton_t:.4f}\", f\"{torch_t:.4f}\"])\n",
        "\n",
        "# Print the table\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-StcfW4a5--",
        "outputId": "bfa1ceeb-5e0b-487c-e940-e2c6b8d11fcf"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------------+-------------------+\n",
            "|      Shape      | Triton Time (ms) | PyTorch Time (ms) |\n",
            "+-----------------+------------------+-------------------+\n",
            "|  (2, 8, 64, 64) |      0.0362      |       0.0360      |\n",
            "| (2, 16, 32, 32) |      0.0343      |       0.0360      |\n",
            "|  (4, 8, 64, 64) |      0.0332      |       0.0362      |\n",
            "| (4, 16, 32, 32) |      0.0346      |       0.0363      |\n",
            "+-----------------+------------------+-------------------+\n"
          ]
        }
      ]
    }
  ]
}